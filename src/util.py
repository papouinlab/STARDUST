# util.py
import os, io, math, scipy, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
from PIL import Image
 
def find_files(input_dir, keyword):
    '''takes an input directory and find the trace csv file, ROA mask tif, cell mask tif, and metadata path'''

    input_files = os.listdir(input_dir)
    input_files = [f.lower() for f in input_files]

    exp_index = [keyword.lower() in f for f in input_files]
    exp_files = np.take(input_files, np.where(exp_index)[0])
    csv_index = ['signal.csv' in f for f in exp_files]

    tif_index = ['.tif' in f for f in exp_files]
    tif_files = np.take(exp_files, np.where(tif_index)[0])
    ROA_index = ['roa' in f for f in tif_files]
    cell_index = ['cell' in f for f in tif_files]
    
    csv_path = os.path.join(input_dir, exp_files[csv_index.index(True)])
    ROA_mask_path = os.path.join(input_dir, tif_files[ROA_index.index(True)])
    cell_mask_path = os.path.join(input_dir, tif_files[cell_index.index(True)])
    
    print("Found the following files: \n")
    print("CSV file: ", csv_path)
    print("ROA mask: ", ROA_mask_path)
    print("Cell mask: ", cell_mask_path)

    return csv_path, ROA_mask_path, cell_mask_path

def read_tif(tif_path, type):

    '''
    read a binary tif file and return the labeled matrix and the number of labels

    ROAs are marked as 1 in the binary matrix
    one ROA is defined as a group of connected pixels (including diagonally connected pixels)
    '''
    print("Reading in file: ", tif_path)
    image = open(tif_path, 'rb').read()
    map_tif = Image.open(io.BytesIO(image))
    map_array = np.asarray(map_tif)

    # determine ROA and number of ROAs
    if type == "ROA":
        map_labeled, map_count = scipy.ndimage.label(map_array, structure = [[1,1,1],[1,1,1],[1,1,1]])
        print("This ROA mask contains", str(map_count), "ROAs.")
    elif type == "cell":
        map_labeled, map_count = scipy.ndimage.label(map_array) 
        print("This cell mask contains", str(map_count), "cells.")
    print("\n")

    return map_array, map_labeled, map_count

def visualize_map(ROA_map_array, cell_map_array):

    '''visualize the ROA and cell masks from binary numpy array'''

    fig, axs = plt.subplots(1,2, figsize = (10, 10))

    axs[0].imshow(ROA_map_array)
    axs[0].set_title('ROA mask')
    axs[1].imshow(cell_map_array)
    axs[1].set_title('Cell mask')
    plt.show()

def raw_to_filtered(csv_path, order = 4, cutoff = 0.4):
    '''
    read in and convert raw traces to filtered traces
    '''
    
    # read in the csv data file in as a dataframe and transpose
    # the csv file has no header and first column is the number of ROA
    # in the original data frame, each row represents a frame and each column represents a ROA
    print("Reading in file: ", csv_path, "\n\n")
    raw_data = pd.read_csv(csv_path, header = None, index_col = 0)
    # transpose data so that each row represents a ROA and each column represents a frame
    # and transform to a numpy 2D array containing # of ROA lists,
    # each list containing signal in each frame for this ROA
    raw_traces = raw_data.transpose().to_numpy() 

    # apply a lowpass Butterworth filter with a 4th order filter at the cutoff of 0.4 Hz
    print("Applying a lowpass Butterworth filter with a", str(order), "th order filter at the cutoff of", str(cutoff), "Hz")
    b, a = scipy.signal.butter(order, cutoff, 'low', analog=False)
    filtered_traces = scipy.signal.filtfilt(b, a, raw_traces)

    return raw_traces, filtered_traces

def check_traces(traces):
    ''' 
    check the raw traces and print out the number of ROA and the number of frames 
    '''
    
    (ROA_count, frame_count) = traces.shape

    print("The current file contains: ")
    print("Number of ROA: ", ROA_count)
    print("Number of frames: ", frame_count)
    return ROA_count, frame_count

def correct_shift(filtered_traces, correction_factor = 0.5):
    
    '''
    'correct' the shift of baseline level in traces using linear regression for subsequent baseline determination
    specifically, corrected traces are generated by subtracting correction_factor (default 0.5) * slope at the current x location from the input traces
    
    note that this correction is not necessary if the baseline is stable
    and that this correction should not be applied to recordings when there is obvious z shift

    prints out the distribution of slopes
    return the corrected traces and dataframe containing slope and intercept of regression
    '''

    (ROA_count, frame_count) = filtered_traces.shape

    slope = []
    intercept = []
    x = np.arange(frame_count)

    for i_ROA in range(ROA_count):
        lm = scipy.stats.linregress(x, filtered_traces[i_ROA])
        slope.append(lm.slope)
        intercept.append(lm.intercept)
    reg = pd.DataFrame({'slope': slope, 'intercept': intercept})
    slope = np.array(slope)
    corrected_traces = filtered_traces - correction_factor * x * slope[:,None]

    # visualize distribution of lm slope
    sns.histplot(reg.slope).set(title = 'Slope distribution histogram')
    return corrected_traces, reg

def check_correction(filtered_traces, corrected_traces, reg):

    '''visual checkpoint for correction'''

    vis_threshold = float(input("Enter the slope cutoff (absolute value) for visualizing correction:"))

    (ROA_count,frame_count) = filtered_traces.shape
    x = np.arange(frame_count)

    for i_ROA in range(ROA_count):
        if abs(reg.slope[i_ROA]) > vis_threshold:
            plt.figure()
            plt.plot(x,filtered_traces[i_ROA],'b-', label = 'original trace')
            plt.plot(x, x * reg.slope[i_ROA] + reg.intercept[i_ROA], 'r-', label = 'regression line')
            plt.plot(x, corrected_traces[i_ROA], 'g-', label = 'corrected trace')
            plt.legend(loc = "upper left")
            plt.title('ROA ' + str(i_ROA + 1)) # ROA ID starts from 1
            plt.show()

def pull_largeslope_traces(ROA_count, reg):
    '''
    Pull out ROA IDs that have user-defined large slope for further inspection.
    '''

    reg_threshold = float(input("Enter the slope cutoff (absolute value) to pull out for check later:"))
    check_ROAs = []

    for i_ROA in range(ROA_count):
        if abs(reg.slope[i_ROA]) > reg_threshold:
            check_ROAs.append(i_ROA + 1) # ROA ID starts from 1
    
    print(f"The following ROAs have a slope larger than {reg_threshold} or smaller than {-reg_threshold}:", check_ROAs)
    return check_ROAs

def find_roots(trace, threshold):
    '''
    input trace (1D array) and threshold (one number)
    look for where the signal crosses threshold
    return the x axis intercepts where the signal crosses threshold 
    '''

    # this function does not account for when one point of signal is AT the threshold
    # which I guess rarely happens anyway

    trace_adjusted = trace - threshold
    cross_bool = np.abs(np.diff(np.sign(trace_adjusted))).astype(bool)
    
    y1 = trace_adjusted[:-1][cross_bool]
    y2 = trace_adjusted[1:][cross_bool]
    x1 = np.where(cross_bool)[0]
    x0 = x1 - y1/(y2-y1) # solve for the x axis intercept (AKA when y=0)
    return x0

def find2points(x, array):
    '''
    given a specific number x and an array containing numbers (arranged from smallest to largest)
    find the closest two flanking numbers of x inside the array
    '''
    for index in range(len(array)):
        if x - array[index] < 0:
            lpoint = array[index-1]
            rpoint = array[index]
            break
    return (lpoint, rpoint)

def find_signal_boundary(trace, signal_threshold, baseline_threshold, include_end_incomplete = False):
    ''' 
    takes a 1D trace, signal_threshold, and baseline_threshold (to call beginning and end of an event)
    return tuples of event start and end points (frames) 
    '''
    # find intercepts for signal and baseline
    signal_intercept = find_roots(trace, signal_threshold)
    baseline_intercept = find_roots(trace, baseline_threshold)

    signal_list = [] # stores the start and end points of each signal event
    for i in signal_intercept:
        if i > baseline_intercept[0] and i < baseline_intercept[-1]: 
            (lpoint, rpoint) = find2points(i,baseline_intercept)
            if (lpoint, rpoint) not in signal_list:
                signal_list.append((lpoint, rpoint))
        elif include_end_incomplete == True and i > baseline_intercept[-1]: # incomplete signal at the end of the trace
            (lpoint, rpoint) = (baseline_intercept[-1], len(trace)) 
            if (lpoint, rpoint) not in signal_list:
                signal_list.append((lpoint, rpoint))

    # find frame numbers for start and end of signals
    signal_boundary = [(math.floor(lpoint),math.ceil(rpoint)) for (lpoint,rpoint) in signal_list] 
    return signal_boundary, signal_intercept, baseline_intercept

def calc_dff(traces, signal_frames = None, baseline_start = 0, baseline_end = -1):

    ''' 
    generates df/f traces based on signal frames 
    designed to work with filtered/smoothed traces but can also work on raw traces
    returns two two-dimensional arrays: dff_traces and dff_traces_nosignal

    Args:
    traces: a two-dimensional array of traces, each row represents a ROA and each column represents a frame
    signal_frames: a two-dimensional boolean array corresponding to each ROA and each frame, true if frame is considered as signal
    baseline_start: optional, the starting frame for baseline calculation, default 0
    baseline_end: optional, the ending frame for baseline calculation, default -1 (end of the trace)

    Returns:
    dff_traces: a two-dimensional array of delta F/F trace based on the provided thresholds
    dff_traces_nosignal: a two-dimensional array of delta F/F trace based on the provided thresholds but free of signal frames (signal frames are set as NaN)
    '''

    # generate a two-dimensional array from traces but free of signal frames
    if signal_frames is None: 
        signal_frames = np.zeros(traces.shape) # if signal_frames are not provided, assume no frame is signal
    traces_nosignal = np.multiply(traces, signal_frames == False) # set signal frames to 0
    traces_nosignal[traces_nosignal == 0] = np.nan # change 0 to nan to remove signal frames in calculation
    
    # calculate the baseline averages from signal-removed traces (ignoring nan) and generate dF/F traces
    baselines = np.nanmean(traces_nosignal[:,baseline_start:baseline_end], axis = 1) 
    dff_traces = (traces - baselines[:,None])/baselines[:,None] 

    dff_traces_nosignal = np.multiply(dff_traces, signal_frames == False) # set signal frames to 0
    dff_traces_nosignal[dff_traces_nosignal == 0] = np.nan # change 0 to nan to remove signal frames in calculation

    return dff_traces, dff_traces_nosignal


    ''' 
    generates df/f traces based on signal frames 
    designed to work with filtered/smoothed traces but can also work on raw traces
    returns two two-dimensional arrays: dff_traces and dff_traces_nosignal

    Args:
    traces: a two-dimensional array of traces, each row represents a ROA and each column represents a frame
    signal_frames: a two-dimensional boolean array corresponding to each ROA and each frame, true if frame is considered as signal
    baseline_start: optional, the starting frame for baseline calculation, default 0
    baseline_end: optional, the ending frame for baseline calculation, default -1 (end of the trace)

    Returns:
    dff_traces: a two-dimensional array of delta F/F trace based on the provided thresholds
    dff_traces_nosignal: a two-dimensional array of delta F/F trace based on the provided thresholds but free of signal frames (signal frames are set as NaN)
    '''

    # generate a two-dimensional array from traces but free of signal frames
    if signal_frames is None: 
        signal_frames = np.zeros(traces.shape) # if signal_frames are not provided, assume no frame is signal
    traces_nosignal = np.multiply(traces, signal_frames == False) # set signal frames to 0
    traces_nosignal[traces_nosignal == 0] = np.nan # change 0 to nan to remove signal frames in calculation
    
    # calculate the baseline averages from signal-removed traces (ignoring nan) and generate dF/F traces
    baselines = np.nanmean(traces_nosignal[:,baseline_start:baseline_end], axis = 1) 
    dff_traces = (traces - baselines[:,None])/baselines[:,None] 

    dff_traces_nosignal = np.multiply(dff_traces, signal_frames == False) # set signal frames to 0
    dff_traces_nosignal[dff_traces_nosignal == 0] = np.nan # change 0 to nan to remove signal frames in calculation

    return dff_traces, dff_traces_nosignal

def find_signal_frames(filtered_traces, signal_frames = None, signal_threshold = 3, baseline_start = 0, baseline_end = -1, include_incomplete = False):
   
    '''
    finds signals in the filtered traces using signal_threshold and onset_threshold
    signal is defined as any event that is larger than signal_threshold * SD of the dF/F trace (default 2SD)

    Args:
        filtered_traces: a two-dimensional array of filtered traces
        signal_frames: a two-dimensional boolean array corresponding to each ROA and each frame, true if frame is considered as signal
        signal_threshold (int or float): optional, signal_threshold (3 as default) * dF/F baseline SD as signal threshold
        baseline_start: optional, the starting frame for baseline calculation, default 0 (beginning of the recording)
        baseline_end: optional, the ending frame for baseline calculation, default -1 (end of the recording)


    Returns:
        dff_traces: a two-dimensional array of delta F/F trace based on the provided thresholds
        signal_frames: a two-dimensional boolean array corresponding to each ROA and each frame, true if frame is considered as signal 
        signal_boundaries: each ROA has a list of tuples of event start and end points
    '''
    
    dff_traces, dff_traces_nosignal = calc_dff(filtered_traces, signal_frames, baseline_start, baseline_end) 
    baselines = np.nanmean(dff_traces_nosignal[:,baseline_start:baseline_end], axis = 1) # calculate the baseline averages from signal-removed dff traces (ignoring nan)
    thresholds = signal_threshold * np.nanstd(dff_traces_nosignal[:,baseline_start:baseline_end], axis = 1) # calculate the baseline standard deviations from signal-removed dff traces (ignoring nan)
    
    # initialize a new array to store signal frames
    ROA_count, frame_count = filtered_traces.shape
    new_signal_frames = np.zeros((ROA_count, frame_count))
    signal_boundaries = []

    # iterate through each ROA to find signals
    for i_ROA in range(0, ROA_count):
        signal_boundary, _ , _ = find_signal_boundary(dff_traces[i_ROA,], thresholds[i_ROA], baselines[i_ROA], include_incomplete)
        signal_boundaries.append(signal_boundary)

        for j_frame in range(0, frame_count):
            for (l,r) in signal_boundary:
                if j_frame >= l and j_frame <= r:
                    new_signal_frames[i_ROA, j_frame] = 1
                    
    return dff_traces, baselines, thresholds, new_signal_frames.astype(bool), signal_boundaries

def iterative_baseline(traces, signal_frames = None, baseline_start = 0, baseline_end = -1, include_incomplete = False):

    '''
    determine the bassline iteratively

    Args:
    traces: a two-dimensional array of traces
    signal_frames: optional, a two-dimensional boolean array corresponding to each ROA and each frame, true if frame is considered as signal
    baseline_start: optional, the starting frame for baseline calculation, default 0 (beginning of the recording)
    baseline_end: optional, the ending frame for baseline calculation, default -1 (end of the recording)
    include_incomplete: optional, include incomplete signals at the end of the trace, default False

    Prompted inputs:
    n_iteration: number of iterations for signal detection
    signal_threshold: signal_threshold * dF/F baseline SD as signal threshold

    Returns:
    dff_traces: a two-dimensional array of delta F/F trace based on the provided thresholds
    baselines: a one-dimensional array of baseline values
    thresholds: a one-dimensional array of signal thresholds
    signal_frames: a two-dimensional boolean array corresponding to each ROA and each frame, true if frame is considered as signal
    signal_boundaries: a list of tuples of event start and end points of each detected activity in each ROA
    '''

    signal_frames_previous = signal_frames
    n_iteration = int(input("Enter the number of iterations for signal detection. We found that most baseline determination stabilize after 6 iterations: "))
    signal_threshold = float(input("Enter the signal threshold for signal detection. Trace fractions where the fluorescence is larger than signal_threshold * SD (suggested value 2-3) are determined as active signal: "))
    print(f"Using signal threshold of {signal_threshold}* SD and detecting baseline from frame {baseline_start} to {baseline_end}.\n")

    for iter in range(n_iteration):
        print(f"Processing round {iter+1} of signal detection...")
        if iter < n_iteration - 1: # only store signal_frames for the initial iterations
            _ , _, _, signal_frames, _ = find_signal_frames(traces, signal_frames_previous, signal_threshold, baseline_start, baseline_end, include_incomplete)
        else:
            dff_traces, baselines, thresholds, signal_frames, signal_boundaries = find_signal_frames(traces, signal_frames_previous, signal_threshold, baseline_start, baseline_end, include_incomplete)
        
        check_ROA(signal_frames) # check current signal detection results
        signal_frames_previous = signal_frames
        print()
    
    return dff_traces, baselines, thresholds, signal_frames, signal_boundaries, signal_threshold

def check_ROA(signal_frames):
    '''check and report how many ROAs have signals'''
    ROAs_with_signal = np.sum(signal_frames, axis = 1) > 0

    print("ROAs with signal: ", np.sum(ROAs_with_signal))
    print("ROAs without signal: ", np.sum(ROAs_with_signal == False))

def analyze_signal(dff_traces, signal_frames, signal_boundaries, frame_rate, drug_frame):

    '''analyze the signals and return a dataframe with signal stats (columns) for each individual signal/event (rows)'''
    

    (ROA_count, frame_count) = dff_traces.shape 
    noise = np.multiply(dff_traces, signal_frames == False).max(axis = 1) # extract baseline noise (max amplitude within baseline) for each ROA

    # initialize lists to store signal stats
    ROA_ID = []
    start_frame = []
    start_time = []
    end_frame = []
    end_time = []
    AUC = []
    amplitude = []
    signal_to_noise = []
    peak_frame = []
    peak_time = []
    rise_time = []
    decay_time = []
    half_width = []
    duration = []
    inter_event_interval = []

    # iterate through each ROA to extract signal stats
    for i_ROA in range(0, ROA_count):

        for j_signal in range(0,len(signal_boundaries[i_ROA])):

            (lpoint, rpoint) = signal_boundaries[i_ROA][j_signal]
            ROA_ID.append(i_ROA + 1)
            
            if rpoint + 1 > frame_count: # if the current signal is an incomplete signal at the end of the trace
                
                start_frame.append(lpoint + 1)
                start_time.append(lpoint/frame_rate)
                end_frame.append(np.nan)
                end_time.append(np.nan)
                event_trace = dff_traces[i_ROA,lpoint:rpoint+1]

                AUC.append(np.nan) # AUC not calculatable
                amplitude.append(max(event_trace))  # signal amplitude
                signal_to_noise.append(max(event_trace)/noise[i_ROA]) # signal to noise ratio

                max_index = np.array([np.argmax(event_trace)]) # max dff index/frame number within the signal/event range
                peak_frame.append(lpoint + max_index[0]) # max dff index (frame number) within the whole trace 
                peak_time.append(peak_frame[-1]/frame_rate) # peak time in seconds

                half = scipy.signal.peak_widths(event_trace, max_index, rel_height=0.5)
                prct_10 = scipy.signal.peak_widths(event_trace, max_index, rel_height=0.1)
                prct_90 = scipy.signal.peak_widths(event_trace, max_index, rel_height=0.9)

                rise_time.append((prct_10[2][0] - prct_90[2][0])/frame_rate) # rise time in seconds
                decay_time.append(np.nan) # decay time in seconds
                half_width.append(np.nan) # full width at half maximum in seconds
                duration.append(np.nan) # duration of the signal/event in seconds
            
            else:
                start_frame.append(lpoint + 1)
                start_time.append(lpoint/frame_rate)
                end_frame.append(rpoint + 1)
                end_time.append(rpoint/frame_rate)

                event_trace = dff_traces[i_ROA,lpoint:rpoint+1] # subset out only the signal/event

                AUC.append(scipy.integrate.simpson(event_trace, dx = 1/frame_rate)) # area under the curve using Simpson's rule
                amplitude.append(max(event_trace))  # signal amplitude
                signal_to_noise.append(max(event_trace)/noise[i_ROA]) # signal to noise ratio

                max_index = np.array([np.argmax(event_trace)]) # max dff index/frame number within the signal/event range
                peak_frame.append(lpoint + max_index[0]) # max dff index (frame number) within the whole trace 
                peak_time.append(peak_frame[-1]/frame_rate) # peak time in seconds

                half = scipy.signal.peak_widths(event_trace, max_index, rel_height=0.5)
                prct_10 = scipy.signal.peak_widths(event_trace, max_index, rel_height=0.1)
                prct_90 = scipy.signal.peak_widths(event_trace, max_index, rel_height=0.9)

                rise_time.append((prct_10[2][0] - prct_90[2][0])/frame_rate) # rise time in seconds
                decay_time.append((prct_90[3][0] - prct_10[3][0])/frame_rate) # decay time in seconds
                half_width.append(half[1][0]/frame_rate) # full width at half maximum in seconds
                duration.append((rpoint - lpoint)/frame_rate) # duration of the signal/event in seconds

            if j_signal == 0:
                inter_event_interval.append(None) # initialize inter-event interval for thr first signal as None
            else:
                inter_event_interval.append((lpoint + 1 - end_frame[-2])/frame_rate) # calculate inter-event interval from the last event
        
    
    signal_stats = pd.DataFrame({'ROA_ID': ROA_ID, 
                                 'signal_start_frame': start_frame, 
                                 'signal_start_time': start_time,
                                 'signal_end_frame': end_frame, 
                                 'signal_end_time': end_time,
                                 'peak_frame': peak_frame, 
                                 'peak_time': peak_time, 
                                 'AUC': AUC, 
                                 'amplitude': amplitude, 
                                 'signal_to_noise': signal_to_noise,
                                 'rise_time': rise_time, 
                                 'decay_time': decay_time, 
                                 'half_width': half_width, 
                                 'duration': duration,
                                 'inter_event_interval': inter_event_interval})
    
    # add column to indicate if the signal peaks before drug application (baseline) or after (drug)
    if drug_frame == 0:
        signal_stats['epoch'] = 'NA'
    else:
        signal_stats['epoch'] = np.where(signal_stats['peak_frame'] < drug_frame, 'baseline', 'drug')
                                 
    return signal_stats

def align_ROA_cell(ROA_map_labeled, cell_map_labeled, ROA_map_count):
    ''' aline ROA_ID and cell_ID based on the labeled map and returns a dataframe with ROA and cell alignment'''

    ROA = range(1, ROA_map_count+1)
    ROA_cell = []
    ROA_not_assigned = []

    for i_ROA in ROA:
        cell_assigned = cell_map_labeled[ROA_map_labeled == i_ROA] # find corresponding cell ID for each pixel inside a ROA
        most_frequent = scipy.stats.mode(cell_assigned, keepdims = False).mode # find the most common cell ID inside the ROA
        if most_frequent == 0: # if the most common cell ID is 0, then find the second most common cell ID
            if len(np.unique(cell_assigned[cell_assigned != 0])) != 0:
                most_frequent = scipy.stats.mode(cell_assigned[cell_assigned != 0], axis = None).mode
            else:
                ROA_not_assigned.append(i_ROA)
        ROA_cell.append(most_frequent) # assign the most common cell ID for the ROA as its cell registration

    df_ROA_cell = pd.DataFrame({'ROA_ID': ROA, 'cell_ID': ROA_cell})
    if len(ROA_not_assigned) != 0:
        print(f"There are {len(ROA_not_assigned)} ({round(len(ROA_not_assigned)/ROA_map_count * 100,2)}%) ROAs not assigned to any cell.")
        print("ROA IDs:", ROA_not_assigned)
        print("Please double check the cell mask registration. \n")
    print("ROA and cell alignment completed.")
    return df_ROA_cell

def ROA_analysis(signal_stats, df_ROA_cell, frame_count, frame_rate, drug_frame):
    '''analyze the signals based on the ROA and return a dataframe with ROA stats (columns) for each individual ROA (rows)'''

    # calculate the signal stats based on ROA
    
    ROA_based_count = signal_stats.groupby(['ROA_ID', 'epoch'], as_index = False).count()
    ROA_based = signal_stats.groupby(['ROA_ID', 'epoch'], as_index = False).mean()
    ROA_based['signal_count'] = ROA_based_count['AUC']

    # identify ROA type (inactive, stable, on, off, NA) based on activity during baseline and after drug application
    ROA = df_ROA_cell.ROA_ID
    ROA_type = []

    for i_ROA in ROA:
        df = ROA_based[ROA_based.ROA_ID == i_ROA]
        
        if 'NA' in df.epoch.unique():
            ROA_type.append('NA')
        elif 'baseline' in df.epoch.unique() and 'drug' in df.epoch.unique():
            ROA_type.append('stable')
        elif 'baseline' in df.epoch.unique():
            ROA_type.append('off')
        elif 'drug' in df.epoch.unique():
            ROA_type.append('on')
        else:
            ROA_type.append('inactive')

    df_ROA_cell['ROA_type'] = ROA_type
    ROA_based = pd.merge(df_ROA_cell, ROA_based, on = ['ROA_ID', 'cell_ID'], how = 'left')

    ROA_based['signal_count'] = np.where(ROA_based['ROA_type'] == 'inactive', 0, ROA_based['signal_count'])

    # calculate recording total, baseline and drug length (in minutes) for frequency calculation
    total_length_min = frame_count/(frame_rate*60)
    baseline_length_min = drug_frame/(frame_rate*60)
    drug_length_min = total_length_min - baseline_length_min

    ROA_based['rec_length'] = np.nan
    ROA_based['rec_length'] = np.where(ROA_based['epoch'] == 'NA', total_length_min, ROA_based['rec_length'])
    ROA_based['rec_length'] = np.where(ROA_based['ROA_type'] == 'inactive', total_length_min, ROA_based['rec_length'])
    ROA_based['rec_length'] = np.where(ROA_based['epoch'] == 'baseline', baseline_length_min, ROA_based['rec_length'])
    ROA_based['rec_length'] = np.where(ROA_based['epoch'] == 'drug', drug_length_min, ROA_based['rec_length'])
    ROA_based['frequency_permin'] = ROA_based['signal_count']/ROA_based['rec_length']   

    cols = ['ROA_ID','cell_ID','ROA_type','epoch','AUC','amplitude','signal_to_noise','rise_time','decay_time','half_width','duration','inter_event_interval', 'signal_count', 'frequency_permin']
    return ROA_based[cols], df_ROA_cell

def inspect_trace(ROA_IDs, dff_traces, baselines, thresholds, drug_frame):
    
    ''' 
    inspect trace visually with baseline, signal threshold and drug application time indicated
    
    Args:
    ROA_IDs: input ROA_IDs (iterable) to visually inspect
    dff_traces: 2D array of dF/F traces
    baselines: 1D array of baseline values
    thresholds: 1D array of signal thresholds
    drug_frame: frame number of drug application (int)
    '''
    frame_count = dff_traces.shape[1]
    x = np.arange(frame_count)

    for i_ROA in ROA_IDs:
        
        plt.figure(figsize=(10,5))
        plt.plot(x,dff_traces[i_ROA-1],color = 'grey') # indexing with i_ROA - 1 because python...
        plt.axhline(y = baselines[i_ROA-1], color = 'r', linestyle = '-', label = "baseline")
        plt.axhline(y = thresholds[i_ROA-1], color = 'g', linestyle = '-', label = "threshold")
        if drug_frame != 0:
            plt.axvline(x = drug_frame, color = 'b', alpha = 0.5, label = "drug application")
        plt.legend(loc = 'upper left')
        plt.xlabel("Frame")
        plt.ylabel("dF/F")
        plt.title('ROA ID: ' + str(i_ROA))
        plt.show(block = False)

def metadata_output(output_path, file_name, frame_rate, drug_frame, signal_threshold):
    
    '''output metadata to an excel file'''
    metadata = pd.DataFrame({'file_name': [file_name], 'frame_rate': [frame_rate], 'drug_frame': [drug_frame], 'drug_time': [drug_frame/frame_rate],
                             'signal_threshold': [signal_threshold]})
    metadata.to_csv(output_path + 'metadata.csv', index = False)
